# Parsing

Arbitrarily nested things can't be represented as a regular language. We need a parser for our lexer! You can reason this out by looking at a finite state machine with a few states. It can only count up to modulus k, where k is the number of states.

* Lexers output tokens.
* Parsers output parse trees.
* Sometimes these things are combined and sometimes you don't actually keep a tree.

## Context Free Grammar (CFG)

* Programming languages are natrually a recursive structure. Like `if { if { if { } } }`
* Context free grammar is a way to describe these structures.

They contain...
* A set of terminals (T)
* A set of non-terminals (N)
* A start symbol (S) (also, S is a part of N)
* A set of productions, X -> Y<sub>1</sub> ... Y<sub>n</sub>
  * X can't be a terminal (can't be the end)
  * Y can be a non-terminal, a terminal, or {epsilon = ε}

**Example**: Balanced parens

N = {S}
T = {(, )}

Productions:
S -> (S)
S -> ε

**Productions can be read as rules.**

S -> (S) == replacement rules. Anywhere we have S, we can replace it with (S)

1. Begin with a string with only the start symbol S
2. Replace any non-terminal X in the string by the right-hand side of some production X -> Y<sub>1</sub>...Y<sub>n</sub>

Then you can repeat when there are no non-terminals left (and then we're done).

There is a general way of writing a string can be transformed into an equivalent string.

Terminals are TOKENS that are generated by the lexer.

**Example:** Fragment of Cool

Expr -> if EXPR then EXPR else EXPR fi

Non-terminals = caps (EXPR above)
Terminals = lowercase (if, then, else, fi)

**Alternatives** are written out with | blocks like...

```
Expr -> if EXPR then EXPR else EXPR fi
      | while EXPR loop EXPR pool
      | id
      | ... and so on
```

